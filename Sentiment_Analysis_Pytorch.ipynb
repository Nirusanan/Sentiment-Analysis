{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -q \"gdown==4.6\""
      ],
      "metadata": {
        "id": "Y5avTRhr_uvm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 19TGf1A2MwlBlYM1ORKJREjP77Y1dGoB7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn7qK5e8dloB",
        "outputId": "3e4d101b-b6dd-4eea-b570-4e27b54ea472"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19TGf1A2MwlBlYM1ORKJREjP77Y1dGoB7\n",
            "To: /content/training.1600000.processed.noemoticon.csv\n",
            "100% 239M/239M [00:01<00:00, 121MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tokenizers import Tokenizer, pre_tokenizers, trainers\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer"
      ],
      "metadata": {
        "id": "GdnsTZPQdu0B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/training.1600000.processed.noemoticon.csv\", encoding='latin')"
      ],
      "metadata": {
        "id": "fkeRIaJ3dmjh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['polarity','id', 'date','query', 'user', 'text']"
      ],
      "metadata": {
        "id": "AY75pMLvdmsu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJneaL1qdmwg",
        "outputId": "cb62fea3-67aa-44d2-810e-907f3af0e32f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          is upset that he can't update his Facebook by ...\n",
              "1          @Kenichan I dived many times for the ball. Man...\n",
              "2            my whole body feels itchy and like its on fire \n",
              "3          @nationwideclass no, it's not behaving at all....\n",
              "4                              @Kwesidei not the whole crew \n",
              "                                 ...                        \n",
              "1599994    Just woke up. Having no school is the best fee...\n",
              "1599995    TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599996    Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599997    Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599998    happy #charitytuesday @theNSPCC @SparksCharity...\n",
              "Name: text, Length: 1599999, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "userPattern = '@[^\\s]+'\n",
        "alphaPattern = \"[^a-zA-Z0-9]\"\n",
        "\n",
        "def process_tweet(tweet):\n",
        "  tweet = tweet.lower()\n",
        "\n",
        "  #Replace all URls\n",
        "  tweet = re.sub(urlPattern,'',tweet)\n",
        "  #Removing all userName\n",
        "  tweet = re.sub(userPattern, '', tweet)\n",
        "  #Remove punctuations\n",
        "  tweet = tweet.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
        "\n",
        "  return tweet"
      ],
      "metadata": {
        "id": "nm6giIJNedkR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['preprocessed_tweets'] = df['text'].apply(lambda x: process_tweet(x))\n",
        "print(\"Text pre-processing is done\")"
      ],
      "metadata": {
        "id": "7PtaPJlxedkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc49c5a7-11ad-4464-9360-620de0995a48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text pre-processing is done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['preprocessed_tweets']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8g8ZP9qdm7_",
        "outputId": "c0858eda-ddf6-42ee-bc5c-d4ab578160a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          is upset that he cant update his facebook by t...\n",
              "1           i dived many times for the ball managed to sa...\n",
              "2            my whole body feels itchy and like its on fire \n",
              "3           no its not behaving at all im mad why am i he...\n",
              "4                                        not the whole crew \n",
              "                                 ...                        \n",
              "1599994    just woke up having no school is the best feel...\n",
              "1599995    thewdbcom  very cool to hear old walt intervie...\n",
              "1599996    are you ready for your mojo makeover ask me fo...\n",
              "1599997    happy 38th birthday to my boo of alll time tup...\n",
              "1599998                             happy charitytuesday    \n",
              "Name: preprocessed_tweets, Length: 1599999, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['polarity'] = df['polarity'].replace({4: 1})"
      ],
      "metadata": {
        "id": "7fT18IzB7_1w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, trainers, pre_tokenizers\n",
        "from tokenizers.models import BPE"
      ],
      "metadata": {
        "id": "9W8fgeTTn4hN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = Tokenizer(BPE())\n",
        "\n",
        "# Set pre-tokenizer\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "# Prepare a trainer for the tokenizer\n",
        "trainer = BpeTrainer()\n",
        "\n",
        "# Train the tokenizer on the text data\n",
        "tokenizer.train_from_iterator(df['preprocessed_tweets'].tolist(), trainer=trainer)\n",
        "\n",
        "# Enable padding to a length of 60 tokens and truncation to a maximum length of 60 tokens\n",
        "tokenizer.enable_padding(length=100)\n",
        "tokenizer.enable_truncation(max_length=100)\n",
        "\n",
        "# Encode the text column and get the IDs with padding and truncation\n",
        "df['encoded'] = df['preprocessed_tweets'].apply(lambda x: tokenizer.encode(x).ids)"
      ],
      "metadata": {
        "id": "h8kMdjMsn4kE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LkkSVhh_qCu",
        "outputId": "364c8e93-d69e-48f2-d85f-ff79b0d4e673"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          [136, 1655, 178, 176, 269, 1326, 564, 1295, 40...\n",
              "1          [18, 13, 2982, 786, 728, 155, 130, 973, 3289, ...\n",
              "2          [147, 1104, 893, 1191, 5004, 144, 244, 209, 12...\n",
              "3          [142, 209, 210, 14041, 129, 165, 164, 523, 425...\n",
              "4          [210, 130, 1104, 3987, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
              "                                 ...                        \n",
              "1599994    [201, 937, 190, 601, 142, 503, 136, 130, 555, ...\n",
              "1599995    [130, 32, 7305, 337, 265, 624, 123, 707, 669, ...\n",
              "1599996    [214, 143, 427, 155, 257, 10881, 11284, 1135, ...\n",
              "1599997    [439, 3, 4987, 785, 123, 147, 779, 162, 7325, ...\n",
              "1599998    [439, 25661, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "Name: encoded, Length: 1599999, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded'].apply(len).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEfHidzjn4nQ",
        "outputId": "37e55660-7cfa-4354-ca72-1cda4113b8fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded'].apply(len).min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvN5XNl5BAc-",
        "outputId": "ece968f7-c5b7-447a-9aa8-fcc6fa093082"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.loc[1, 'encoded'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oJ06F2jPMRN",
        "outputId": "873b07f5-6cc0-424d-ca08-5de43c09ee92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18, 13, 2982, 786, 728, 155, 130, 973, 3289, 123, 1983, 1675, 130, 932, 158, 183, 162, 27911, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode a specific row, e.g., the second row (index 1)\n",
        "encoded_row = df.loc[1, 'encoded']\n",
        "decoded_text = tokenizer.decode(encoded_row)\n",
        "\n",
        "# Display the decoded text\n",
        "print(\"Decoded text from the second row:\")\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrB_eN9on4p_",
        "outputId": "43d96e56-3942-4af0-fa1b-f9a608bc0ace"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded text from the second row:\n",
            "i d ived many times for the ball managed to save 50 the rest go out of bounds 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df['encoded'].values"
      ],
      "metadata": {
        "id": "YfuDXvQ4n4st"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([np.array(lst) for lst in x])"
      ],
      "metadata": {
        "id": "5-qW8D5mn454"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "dViHzWWyzqkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7407637-f4ca-450f-ece0-d38e2a9551a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1599999, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['polarity'].values"
      ],
      "metadata": {
        "id": "87S98lcmzqni"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "AGpAWUa4zqq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aea052e-0a01-4959-f4ae-9061caafea8c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1599999,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "WLsEYJExzqxD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cogtb8rC_JRQ",
        "outputId": "9b2b39e4-3f56-4fff-93a9-7a35fff957b4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1119999, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Convert your numpy arrays to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "7Fz_-fJP6Pgk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
      ],
      "metadata": {
        "id": "1zwKq-im6PmS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model with an embedding layer\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "5Br84rKY6PpW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "vocab_size = max(X_train.max(), X_test.max()) + 1  # assuming X_train and X_test contain token IDs starting from 0\n",
        "embed_size = 128\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "num_classes = len(torch.unique(y_train_tensor))\n",
        "\n",
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTrd3qLH6Prw",
        "outputId": "4f4f992c-8e67-4907-bbfa-ef2dd57eaa0a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMClassifier(vocab_size, embed_size, hidden_size, num_layers, num_classes)\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxo5b-cC7vXH",
        "outputId": "cc349087-41bd-456b-e71f-f75a52621911"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (embedding): Embedding(30000, 128)\n",
              "  (lstm): LSTM(128, 512, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "G2jj7Eyd6Pug"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to('cuda' if torch.cuda.is_available() else 'cpu'), y_batch.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to('cuda' if torch.cuda.is_available() else 'cpu'), y_batch.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeYkm9bc6PxU",
        "outputId": "11818cca-a042-434c-e4ea-e932fc55f615"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.6931, Accuracy: 50.13%\n",
            "Epoch [2/5], Loss: 0.3849, Accuracy: 80.73%\n",
            "Epoch [3/5], Loss: 0.3718, Accuracy: 82.59%\n",
            "Epoch [4/5], Loss: 0.3750, Accuracy: 83.01%\n",
            "Epoch [5/5], Loss: 0.2615, Accuracy: 82.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict polarity for a given text\n",
        "def predict_polarity(text, tokenizer, model):\n",
        "    # Encode the input text\n",
        "    encoded_text = tokenizer.encode(text).ids\n",
        "    # Pad/truncate to the required length\n",
        "    encoded_text = encoded_text[:100] + [0] * (100 - len(encoded_text))\n",
        "    # Convert to tensor\n",
        "    input_tensor = torch.tensor(encoded_text, dtype=torch.long).unsqueeze(0)\n",
        "    input_tensor = input_tensor.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # Predict polarity\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "    return predicted.item()\n",
        "\n",
        "data = \"This is a good example\"\n",
        "polarity = predict_polarity(data, tokenizer, model)\n",
        "print(f'The polarity of the given text \"{data}\" is {polarity}')"
      ],
      "metadata": {
        "id": "SibvVBKz6MF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657bffb5-9182-4a8f-f02c-43af19017014"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The polarity of the given text \"This is a good example\" is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NDF9x-62n4_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}